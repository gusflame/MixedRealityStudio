# Session 03 - 08/29/17


## Intro and Recap
* Miscellaneous reminders:
    * Still some new faces today. Probably last day that we'll have new people. I think you guys have filled up my class.
    * Remember that lecture slides, notes, and reading will be on [github](https://github.com/ivaylopg/Tech421Tech3706)
    * First session of each week will usually be talking/discussion, second sessions will be more technical.
* Topic Recap
    * We want to come up with a working definition of AR/VR
        * _Inducing targeted behavior in an organism by using artificial sensory stimulation, while the organism has little or no awareness of the interference._ - LaValle
        * Immanuel Kant - Dual nature of reality
            * Physical world vs perceived world.
    * As far as this class is concerned, we’re drawing the line here:
        * **Virtual Reality** = Where everything that the user sees & hears is controlled by the created experience. 
        * **Augmented Reality** = You are adding things to the real world.
    * Difference b/w layering content on top of the world (Google Glass) and being part of the world
    * Talked about hololens as not the most ideal device in the real world but our ideal lab device
    * Two **huge** technologies that make it a killer AR headset
        * **Display** and **Sensors**
        * The Hololens is made by the same company as the Kinect
    * Even though it is not widely available, expensive, and technically only for “developers,” it is **really good at what it can do**.
    * **Creative Coding** is a type of computer programming in which the goal is to create something expressive instead of something functional.
* Fix mistake from last time

## AR/VR design principles continued
### Interaction
* User interaction and expectations
    * What do we mean by **interaction**?
    * Show GUI vs text
* Why are we jumping into code right away?
    * We need code as **Triggers** in what we make
        - Beyond what we set up
        - Lets us change (Do) stuff in the scene
* Designing for interaction
    * What (what is the actual input and output)
    * How do we cue that interaction
    * The technology enables interactions
    * **expectations** and **teaching**
        * Example of baby trying to zoom/pinch on magazine after using iPad
    * **Skeuomorphism**
        * Apple notes/audio apps
* Screens vs Space
    * All of a sudden we have to think about context for what we make
        * VR Deals with it by creating environments
            * Netflix web example, netflix VR example
            * VR "Home" interfaces - need a context for the screens we use
                * Biggest criticism is that people cannot customize their own "home" space
    * Not constrained by available resolution, but by space in the real world
    * Interesting challenge about this is that we're moving towards unknown. There are no answers
    * Scale really matters
        * 1:1 relationship with space
        * AR apps can measure real world units
* Two concepts I want to focus on today:
    * **Manipulation**
        * UI Fidelity/Ease (expectation)
        * Types of manipulation
            * 2D (we take this for granted but it was not always this way)
            * 3D examples
                * Power Glove
                * LEAP sensor
                * Oculus/Vive handles
        * Hololens designers focused on defining a set of interactions to work with
            * gaze
            * two gestures + tracking
            * voice input
                * All the big tech companies have voice plays right now
        * Show 3D/VR keyboard
    * **Exploration**
        * Natural, but limited by available space.
        * Case study: Overheard
        * JPL - 1:1 models of rovers for designers to walk around
        * Exploration can be a manipulation too: content can react to your position

## HoloLens Case Studies
* Think about:
    * Manipulation
    * Exploration
    * Immersion/emotion
    * and most of all why? Why why why?

## Group Exercise
* _When asked, "How could you possibly have done the first interactive graphics program, the first non-procedural programming language, the first object oriented software system, all in one year?" Ivan replied: "Well, I didn't know it was hard.”_
* Come up with examples of:
    * Something Digital you Wish you could touch?
    * Something big you wish you could see small?
    * Something small you wish you could see big?
    * Something invisible you wish you could see?
* Specifically think about places where technology is a _barrier_.
* Combine similar ideas
* Separate complex ideas
* Find Cause & Effect Relationships

## Assignments for next time
* [John Underkoffler - TED Talk and Article](https://thenextweb.com/media/2015/08/31/a-stark-future/)
* [Design For Humanity - Parts 1, 2, 3](https://medium.com/swlh/the-future-of-design-is-emotional-5789ccde17aa)

## Extra reading
**This is not required!** Just some additional resources you might find interesting/relevant/funny.
The **Mother of all Demos** ([video](https://www.youtube.com/watch?v=yJDv-zdhzMY), [wikipedia](https://en.wikipedia.org/wiki/The_Mother_of_All_Demos)) was Douglas Engelbart's first public demonstration of the graphical user interface and is often referred to as one of a handful of distinct events that changed computing forever.    
[The Encyclopedia of Human-Computer Interaction, 2nd Ed.](https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/human-computer-interaction-brief-intro)    
[Skeuomorphism is Dead, Long Live Skeuomorphism](https://www.interaction-design.org/literature/article/skeuomorphism-is-dead-long-live-skeuomorphism)    
[An Open-Source Keyboard to Make Your Own](http://www.normalvr.com/blog/an-open-source-keyboard-to-make-your-own/)    
[Entire Gadget Lab Episode](https://www.youtube.com/watch?v=IcJ-JuA_K7U) of the JPL hololens demo
